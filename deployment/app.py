import os
from webbrowser import get
import av
import sys
sys.path.append(".")
import cv2
import time
import json
import torch
import warnings
import datetime
import numpy as np
import streamlit as st
import matplotlib.pyplot as plt
from PIL import Image, ImageEnhance
from face_recognition.facenet import *
from streamlit_webrtc import webrtc_streamer, RTCConfiguration, WebRtcMode

os.environ["KMP_DUPLICATE_LIB_OK"]="TRUE"

warnings.filterwarnings('ignore')

def detect_faces(img_path):
    if type(img_path) == str:
        image = Image.open(img_path)
        image = np.array(image.convert('RGB'))
        image = cv2.cvtColor(image, 1)
    else:
        image = img_path
        if type(image) != np.ndarray:
            image = np.array(image.convert('RGB'))
        image = cv2.cvtColor(image, 1)

    face = mtcnn(image)
    return face

def add_embedding(face_cropped, user_code):
    new_name = str(user_code)
    new_emb = resnet(face_cropped.to(device).unsqueeze(0)).detach()
    data = [embedding_list.append(new_emb), name_list.append(new_name)]
    torch.save(data, 'deployment/assets/embedding.pt')

def main(img, get_ax=False):
    if get_ax:
        name, faces = recognize(img, get_axes=get_ax)
        if name == 'Unknown' and faces is None:
            return {"name": name}, faces
        return json.load(open(f"deployment/assets/info/{name}.json", 'r')), faces[0]
    
    else:
        name = recognize(img)
        if name == 'Unknown':
            return {"name": name}
        return json.load(open(f"deployment/assets/info/{name}.json", 'r'))

def app():
    """–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –ª–∏—Ü"""

    st.title("–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –ª–∏—Ü")
    st.text("–°–æ–∑–¥–∞–≤–∞—Ç—å —Å –ø–æ–º–æ—â—å—é Streamlit –∏ –≥–ª—É–±–æ–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è")

    activities = ["–û–±–æ –º–Ω–µ", "–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ", "–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è", "–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –≤–µ–±-–∫–∞–º–µ—Ä—ã –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏"]
    choice = st.sidebar.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ", activities)

    if choice == '–û–±–æ –º–Ω–µ':
        st.subheader("–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–æ –ª–∏—Ü—É –∏ –≥–æ–ª–æ—Å—É")
        st.markdown(
            "–°–æ–∑–¥–∞–Ω —Å –ø–æ–º–æ—â—å—é Streamlit [Truong Son](https://github.com/vuongtruongson99). –í–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –ø–æ–∑–≤–æ–ª—è–µ—Ç –¥–æ–±–∞–≤–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –∏ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –µ–≥–æ –ø–æ–∑–∂–µ.")
        st.subheader("–°—Ç—É–¥–µ–Ω—Ç:")
        members = ''' 
            **–í—ã–æ–Ω–≥ –ß—ã–æ–Ω–≥ –®–æ–Ω** - –ò–ö–ë–û-05-19\n'''
        st.markdown(members)
    
    elif choice == '–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ':
        st.subheader("–î–æ–±–∞–≤—å—Ç–µ —Å–≤–æ–µ –ª–∏—Ü–æ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö")
        user_name = st.text_input("–í–∞—à–µ –∏–º—è:")
        user_dob = st.date_input("–î–∞—Ç–∞ —Ä–æ–∂–¥–µ–Ω–∏—è:", min_value=datetime.date(1940, 1, 1))
        user_code = st.text_input("–õ–∏—á–Ω—ã–π –∫–æ–¥:")
        image = st.camera_input("–°–¥–µ–ª–∞—Ç—å —Ñ–æ—Ç–æ")

        if image is not None:
            image = Image.open(image).convert('RGB')
            face = detect_faces(image)

            # Save new image to database
            user_folder = os.path.join('deployment/assets/database', user_code)
            if not os.path.isdir(user_folder):
                os.mkdir(user_folder)
            new_upload_path = os.path.join(user_folder, time.strftime("%Y%m%d%H%M%S.jpg"))
            image.save(new_upload_path)

            # Count number of user in database
            user_counts = len(next(os.walk('deployment/assets/database'))[1])
            print(f"–ù–∞ –¥–∞–Ω–Ω—ã–π –º–æ–º–µ–Ω—Ç –µ—Å—Ç—å {user_counts} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π!!!")

            # Save user's information to json file
            user_info_path = os.path.join(user_folder.replace(f"database\{user_code}", "info"), f"{user_code}.json")
            user_info = {
                "name": user_name,
                "user_code": user_code,
                "user_dob": user_dob.strftime('%m/%d/%Y'),
                "img_num": len([name for name in os.listdir(f'deployment/assets/database/{user_code}') if name.endswith('jpg') or name.endswith('JPG')])
            }
            with open(user_info_path, 'w+') as f:
                json.dump(user_info, f, indent=2)
            
            # Add face cropped to embedding file
            if face is not None:
                add_embedding(face, user_code)
                st.success(f'–ó–∞–≥—Ä—É–∂–µ–Ω–æ: –≤—Å—Ç—Ä–∞–∏–≤–∞–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ!')

    elif choice == '–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è':
        image = st.camera_input("–°–¥–µ–ª–∞—Ç—å —Ñ–æ—Ç–æ")
        if image is not None:
            image = Image.open(image)

            enhace_type = st.sidebar.radio(
                "–ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è", ["–û—Ä–∏–≥–∏–Ω–∞–ª", "–û—Ç—Ç–µ–Ω–∫–∏ —Å–µ—Ä–æ–≥–æ", "–ö–æ–Ω—Ç—Ä–∞—Å—Ç", "–Ø—Ä–∫–æ—Å—Ç—å", "–†–∞–∑–º—ã—Ç–∏–µ"]
            )

            if enhace_type == "–û—Ç—Ç–µ–Ω–∫–∏ —Å–µ—Ä–æ–≥–æ":
                new_img = np.array(image.convert('RGB'))
                img = cv2.cvtColor(new_img, 1)
                result = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
                st.image(result)

            elif enhace_type == "–ö–æ–Ω—Ç—Ä–∞—Å—Ç":
                c_rate = st.sidebar.slider("–ö–æ–Ω—Ç—Ä–∞—Å—Ç", 0.5, 3.5)
                enhacer = ImageEnhance.Contrast(image)
                result = enhacer.enhance(c_rate)
                st.image(result)

            elif enhace_type == "–Ø—Ä–∫–æ—Å—Ç—å":
                c_rate = st.sidebar.slider("–Ø—Ä–∫–æ—Å—Ç—å", 0.5, 3.5)
                enhacer = ImageEnhance.Brightness(image)
                result = enhacer.enhance(c_rate)
                st.image(result)

            elif enhace_type == '–†–∞–∑–º—ã—Ç–∏–µ':
                new_img = np.array(image.convert('RGB'))
                blur_rate = st.sidebar.slider('–†–∞–∑–º—ã—Ç–∏–µ', 0.5, 3.5)
                img = cv2.cvtColor(new_img, 1)
                result = cv2.GaussianBlur(img, (11, 11), blur_rate)
                st.image(result)
            
            else:
                result = image

        if st.button("–ü—Ä–æ—Ü–µ—Å—Å"):
            with st.spinner(text="üê±‚Äçüèç –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ..."):
                data = main(result)
                st.write(data)
                st.balloons()
                # os.remove("recognition.py")

    elif choice == "–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –≤–µ–±-–∫–∞–º–µ—Ä—ã –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏":
        st.warning("–í–Ω–∏–º–∞–Ω–∏–µ: –ß—Ç–æ–±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —ç—Ç–æ—Ç —Ä–µ–∂–∏–º, –≤–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ –≤–µ–±-–∫–∞–º–µ—Ä–µ.")
        message = "üê±‚Äçüëì –ü–æ–¥–æ–∂–¥–∏—Ç–µ —Å–µ–∫—É–Ω–¥—É, –∫–æ–µ-—á—Ç–æ —Å–¥–µ–ª–∞—Ç—å..."

        with st.spinner(message):
            class VideoProcessor:
                def recv(self, frame):
                    frame = frame.to_ndarray(format="bgr24")
                    frame = cv2.cvtColor(frame, 1)
                    
                    info, faces = main(frame, get_ax=True)
                    
                    if faces is None:
                        return av.VideoFrame.from_ndarray(frame, format="bgr24")
                
                    cv2.rectangle(frame, (int(faces[0]), int(faces[1])), (int(faces[2]), int(faces[3])), (0, 255, 0), 3)
                    frame = cv2.putText(frame, info['name'], (int(faces[0]), int(faces[1])), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 1, cv2.LINE_AA)
                    frame = av.VideoFrame.from_ndarray(frame, format="bgr24")
                    return frame
            
            webrtc_streamer(
                key="SOWN",
                video_processor_factory=VideoProcessor,
                media_stream_constraints={"video": True, "audio": False}
            )

if __name__ == '__main__':
    app()